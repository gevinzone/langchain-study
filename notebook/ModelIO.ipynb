{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model IO\n",
    "\n",
    "Model IO ç”± 3 éƒ¨åˆ†æ„æˆï¼š\n",
    "- Prompt Template\n",
    "- Model(LLM)\n",
    "- Output Parser"
   ],
   "id": "7ac8d0d6773fcfbc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prmpt Template",
   "id": "46b6080e7eedf5d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:00:10.519958Z",
     "start_time": "2024-07-07T09:00:10.263670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\n",
    "å¯¹äºå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"price\", \"flower_name\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt)"
   ],
   "id": "ea8b11dfc34b9dda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['flower_name', 'price'] template='æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\\nå¯¹äºå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\\n'\n",
      "input_variables=['flower_name', 'price'] template='æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\\nå¯¹äºå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\\n'\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:00:13.229591Z",
     "start_time": "2024-07-07T09:00:13.227323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = prompt.format(price=10, flower_name=\"ç«ç‘°èŠ±\")\n",
    "print(inputs)"
   ],
   "id": "a617faff1fa078f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\n",
      "å¯¹äºå”®ä»·ä¸º 10 å…ƒçš„ ç«ç‘°èŠ± ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LLM",
   "id": "64413e6e67d67f9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ChatModel",
   "id": "d7e65aba29ee8e79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:00:22.543458Z",
     "start_time": "2024-07-07T09:00:22.246542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "deployment = \"gpt-4o\"\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=deployment,\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "print(llm)"
   ],
   "id": "2f1dcd3bb89dadb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x114232f30> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1150a3fb0> openai_api_key=SecretStr('**********') openai_proxy='' max_tokens=1024 azure_endpoint='https://eus1.openai.azure.com/' deployment_name='gpt-4o' openai_api_version='2023-12-01-preview' openai_api_type='azure'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:00:30.830675Z",
     "start_time": "2024-07-07T09:00:27.669934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = llm.invoke(inputs)\n",
    "print(outputs)\n"
   ],
   "id": "8c2db737e7217e4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°ï¼š\\n\\n---\\n\\nğŸŒ¹ **æµªæ¼«ç«ç‘°ï¼Œä»…éœ€ 10 å…ƒï¼** ğŸŒ¹\\n\\nç”¨è¿™æœµä¼˜é›…çš„ç«ç‘°ä¼ è¾¾æ‚¨çš„çˆ±æ„å’Œæ„ŸåŠ¨ã€‚æ— è®ºæ˜¯é€ç»™å¿ƒçˆ±çš„äººï¼Œè¿˜æ˜¯ä¸ºè‡ªå·±çš„ç”Ÿæ´»å¢æ·»ä¸€æŠ¹ç¾ä¸½ï¼Œè¿™æœµç»å…¸çš„çº¢ç«ç‘°æ°¸è¿œæ˜¯æœ€ä½³é€‰æ‹©ã€‚è®©æ¯ä¸€ä¸ªç¬é—´éƒ½å› ç«ç‘°çš„ç¾ä¸½è€Œå˜å¾—ç‰¹åˆ«ï¼\\n\\n---\\n\\nå¸Œæœ›è¿™ä¸ªæè¿°èƒ½å¸®åŠ©å¸å¼•æ›´å¤šé¡¾å®¢ï¼' response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 48, 'total_tokens': 168}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_abc28019ad', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-a0ffd302-4bf2-498f-aeae-7b0d17218a8c-0' usage_metadata={'input_tokens': 48, 'output_tokens': 120, 'total_tokens': 168}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Completion Model",
   "id": "ce92bb8d04c0e468"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:01:11.084328Z",
     "start_time": "2024-07-07T09:01:11.070524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureOpenAI\n",
    "\n",
    "deployment = \"gpt-35-turbo-instruct\"\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model_name=deployment,\n",
    "    deployment_name=deployment,\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "print(llm)"
   ],
   "id": "683682062fe88cae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mAzureOpenAI\u001B[0m\n",
      "Params: {'deployment_name': 'gpt-35-turbo-instruct', 'model_name': 'gpt-35-turbo-instruct', 'temperature': 0.7, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 1024}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:01:14.807592Z",
     "start_time": "2024-07-07T09:01:12.693178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = llm.invoke(inputs)\n",
    "print(outputs)"
   ],
   "id": "7a9024105f1a3919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"ä»¤äººå¿ƒåŠ¨çš„ç«ç‘°èŠ±ï¼Œåªéœ€10å…ƒï¼Œå°±èƒ½å°†æ‚¨çš„çˆ±æ„ä¼ è¾¾ç»™å¿ƒçˆ±çš„äººã€‚è¿™æœµç«ç‘°èŠ±æ•£å‘ç€æµ“éƒçš„èŠ±é¦™ï¼ŒèŠ±ç“£æŸ”è½¯å¦‚ä¸ï¼Œä»¿ä½›åœ¨å‘æ‚¨å€¾è¯‰çˆ±æƒ…çš„ç”œèœœã€‚æ— è®ºæ˜¯é€ç»™æ‹äººã€æœ‹å‹è¿˜æ˜¯å®¶äººï¼Œéƒ½èƒ½è®©ä»–ä»¬æ„Ÿå—åˆ°æ‚¨çš„çœŸæŒšæƒ…æ„Ÿã€‚èµ¶ç´§å¸¦èµ°è¿™æŸç¾ä¸½çš„ç«ç‘°èŠ±ï¼Œè®©å®ƒè§è¯æ‚¨çš„çˆ±æ„å§ï¼\"\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:02:13.697662Z",
     "start_time": "2024-07-07T09:02:11.757438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = llm(inputs)\n",
    "print(outputs)"
   ],
   "id": "a16b30ebca3b11b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gevin/projects/pycharm/ai/venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"ä»¤äººå¿ƒåŠ¨çš„ç«ç‘°èŠ±ï¼Œä»¥10å…ƒçš„ä»·æ ¼å±•ç°å‡ºæ— ä¸ä¼¦æ¯”çš„ä¼˜é›…å’Œæµªæ¼«ã€‚æ— è®ºæ˜¯é€ç»™å¿ƒçˆ±çš„äººï¼Œè¿˜æ˜¯ç‚¹ç¼€ç”Ÿæ´»ç©ºé—´ï¼Œéƒ½èƒ½å¸¦æ¥æ»¡æ»¡çš„å¹¸ç¦å’Œæ¸©é¦¨ã€‚è®©è¿™æŸé²œè‰³çš„ç«ç‘°èŠ±ï¼Œæˆä¸ºæ‚¨çš„çˆ±æ„å’Œå…³æ€€çš„æœ€ä½³è¡¨è¾¾ã€‚\"\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:28:15.830335Z",
     "start_time": "2024-07-07T09:28:10.609877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flowers = [\"ç«ç‘°\", \"ç™¾åˆ\", \"åº·ä¹ƒé¦¨\"]\n",
    "prices = [\"50\", \"30\", \"20\"]\n",
    "\n",
    "for flower, price in zip(flowers, prices):\n",
    "    inputs = prompt.format(price=price, flower_name=flower)\n",
    "    outputs = llm.invoke(inputs)\n",
    "    print(outputs)"
   ],
   "id": "e89a180ec77b6c78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"50å…ƒçš„ç«ç‘°ï¼Œæ˜¯çˆ±çš„ä»£è¨€ï¼Œæƒ…æ„Ÿçš„æŠ•å°„ã€‚å®ƒæŸ”ç¾çš„èŠ±ç“£æ•£å‘ç€è¿·äººçš„èŠ³é¦™ï¼Œå¸¦æ¥æ¸©æš–å’Œå¹¸ç¦çš„æ„Ÿå—ã€‚æ— è®ºæ˜¯é€ç»™çˆ±äººï¼Œè¿˜æ˜¯è‡ªå·±å“å°ï¼Œéƒ½èƒ½è®©å¿ƒçµæ²‰é†‰å…¶ä¸­ã€‚è®©æˆ‘ä»¬ç”¨è¿™æŸå……æ»¡çˆ±æ„çš„ç«ç‘°ï¼Œä¼ é€’å¿ƒä¸­æœ€çœŸæŒšçš„æƒ…æ„Ÿã€‚\"\n",
      "\n",
      "\"ä¼˜é›…çš„ç™¾åˆï¼Œæ˜¯æµªæ¼«ä¸çº¯æ´çš„è±¡å¾ã€‚æ¯æœµç™¾åˆéƒ½å……æ»¡ç€å¸Œæœ›å’Œç¥ç¦ï¼Œè®©å®ƒä»¬çš„èŠ³é¦™å……æ»¡æ‚¨çš„ç”Ÿæ´»ã€‚ç°åœ¨åªéœ€ 30 å…ƒï¼Œå°±èƒ½å°†è¿™ä»½ç¾å¥½å¸¦ç»™æ‚¨æœ€çˆ±çš„äººã€‚èµ¶å¿«æŠŠå®ƒä»¬å¸¦å›å®¶ï¼Œè®©ç™¾åˆçš„é­…åŠ›ç‚¹äº®æ‚¨çš„ä¸–ç•Œã€‚\"\n",
      "\n",
      "â€œç»½æ”¾åœ¨æ¸…æ™¨çš„åº·ä¹ƒé¦¨ï¼Œå¦‚åŒä¸€æŸæ¸©æŸ”çš„å…‰èŠ’ï¼Œæ•£å‘ç€æ¸…æ–°çš„èŠ±é¦™ã€‚å®ƒä»¬çš„ç²‰å«©è‰²å½©ï¼Œä»¿ä½›æ˜¯å¤©ä½¿ä»¬çš„å¾®ç¬‘ï¼Œæ¸©æš–ç€æ¯ä¸€ä¸ªå¿ƒçµã€‚æ¯ä¸€æœµéƒ½æ˜¯å¦‚æ­¤ç»†è…»ï¼Œå¦‚æ­¤ç¾å¦™ã€‚åªéœ€20å…ƒï¼Œè®©æˆ‘ä»¬æŠŠè¿™ä»½æ¸©æŸ”å¸¦ç»™æ‚¨çš„å¿ƒä¸Šäººã€‚â€\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Output Parser\n",
    "\n",
    "Output Parser èƒ½å¤ŸæŠŠ LLM çš„è¾“å‡ºè½¬æ¢ä¸ºæˆ‘ä»¬æƒ³è¦çš„æ ¼å¼ã€‚æˆ‘ä»¬å¾€å¾€å¸Œæœ› LLM è¾“å‡ºæ˜¯ä¸€ä¸ª JSON æ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œç„¶åæˆ‘ä»¬è§£æè¿™ä¸ªå­—ç¬¦ä¸²ï¼Œå¾—åˆ°ä¸€ä¸ª Python å¯¹è±¡ã€‚\n"
   ],
   "id": "5f75a590fe87d321"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:51:16.188702Z",
     "start_time": "2024-07-07T09:51:16.172743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(\n",
    "        name=\"description\",\n",
    "        description=\"é²œèŠ±çš„æè¿°æ–‡æ¡ˆ\",\n",
    "    ),\n",
    "    ResponseSchema(\n",
    "        name=\"reason\",\n",
    "        description=\"é—®ä»€ä¹ˆè¦è¿™æ ·å†™è¿™ä¸ªæ–‡æ¡ˆ\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "response_format_instructions = output_parser.get_format_instructions()\n",
    "print(response_format_instructions)\n"
   ],
   "id": "6a06da368f25b59d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"description\": string  // é²œèŠ±çš„æè¿°æ–‡æ¡ˆ\n",
      "\t\"reason\": string  // é—®ä»€ä¹ˆè¦è¿™æ ·å†™è¿™ä¸ªæ–‡æ¡ˆ\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T09:55:05.870905Z",
     "start_time": "2024-07-07T09:55:03.115212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_template = \"\"\"æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\n",
    "å¯¹äºå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\n",
    "{response_format_instructions}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    prompt_template,\n",
    "    partial_variables={\"response_format_instructions\": response_format_instructions})\n",
    "print(prompt)\n",
    "outputs = llm.invoke(prompt.format(price=10, flower_name=\"ç«ç‘°èŠ±\"))"
   ],
   "id": "67eea5efe441f5fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['flower_name', 'price'] partial_variables={'response_format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"description\": string  // é²œèŠ±çš„æè¿°æ–‡æ¡ˆ\\n\\t\"reason\": string  // é—®ä»€ä¹ˆè¦è¿™æ ·å†™è¿™ä¸ªæ–‡æ¡ˆ\\n}\\n```'} template='æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„é²œèŠ±åº—æ–‡æ¡ˆæ’°å†™å‘˜ã€‚\\nå¯¹äºå”®ä»·ä¸º {price} å…ƒçš„ {flower_name} ï¼Œæ‚¨èƒ½æä¾›ä¸€ä¸ªå¸å¼•äººçš„ç®€çŸ­æè¿°å—ï¼Ÿ\\n{response_format_instructions}'\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T12:04:31.327031Z",
     "start_time": "2024-07-07T12:04:31.324738Z"
    }
   },
   "cell_type": "code",
   "source": "print(outputs)",
   "id": "3749585a99fc76d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'è¿™æŸç²¾ç¾çš„ç«ç‘°ï¼ŒèŠ±æœµé¥±æ»¡ï¼Œè‰²å½©è‰³ä¸½ï¼Œæ•£å‘ç€è¿·äººçš„é¦™æ°”ã€‚å®ƒæ˜¯æœ€ä½³çš„ç¤¼ç‰©é€‰æ‹©ï¼Œå¯ä»¥è¡¨è¾¾æ‚¨å¯¹å¿ƒçˆ±ä¹‹äººçš„çœŸæŒšæƒ…æ„Ÿã€‚', 'reason': 'ç«ç‘°æ˜¯æœ€ç»å…¸çš„é²œèŠ±ä¹‹ä¸€ï¼Œè±¡å¾ç€çˆ±æƒ…å’Œæµªæ¼«ï¼Œä»·æ ¼é€‚ä¸­ï¼Œèƒ½å¤Ÿå¸å¼•ç›®æ ‡é¡¾å®¢çš„æ³¨æ„åŠ›ã€‚è¿™æ ·çš„æ–‡æ¡ˆèƒ½å¤Ÿçªå‡ºé²œèŠ±çš„ç¾ä¸½ç‰¹ç‚¹ï¼Œè®©é¡¾å®¢äº§ç”Ÿè´­ä¹°æ¬²æœ›ã€‚'}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T12:05:43.320462Z",
     "start_time": "2024-07-07T12:05:36.730415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "flowers = [\"ç«ç‘°\", \"ç™¾åˆ\", \"åº·ä¹ƒé¦¨\"]\n",
    "prices = [\"50\", \"30\", \"20\"]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"flower_name\", \"price\", \"description\", \"reason\"])\n",
    "\n",
    "for flower, price in zip(flowers, prices):\n",
    "    inputs = prompt.format(price=price, flower_name=flower)\n",
    "    outputs = llm.invoke(inputs)\n",
    "    outputs = output_parser.parse(outputs)\n",
    "    outputs[\"flower_name\"] = flower\n",
    "    outputs[\"price\"] = price\n",
    "    print(len(df))\n",
    "    df.loc[len(df)] = outputs\n",
    "    \n",
    "print(df)\n"
   ],
   "id": "d5559df4a01701c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "  flower_name price                                        description  \\\n",
      "0          ç«ç‘°    50  è¿™æŸç²‰è‰²ç«ç‘°ï¼ŒèŠ±æœµé¥±æ»¡ï¼Œè‰²å½©é²œè‰³ï¼Œæ•£å‘ç€æ·¡æ·¡çš„èŠ±é¦™ã€‚å®ƒæ˜¯é€ç»™å¿ƒçˆ±çš„äººæœ€ç”œèœœçš„è¡¨ç™½ï¼Œä¹Ÿæ˜¯æœ€æ¸©æŸ”...   \n",
      "1          ç™¾åˆ    30  ç™¾åˆï¼Œè±¡å¾ç€çº¯æ´å’Œé«˜è´µï¼Œæ˜¯é€ç»™å¿ƒçˆ±çš„äººæœ€å¥½çš„ç¤¼ç‰©ã€‚è¿™æŸé²œèŠ±çš„å”¯ç¾ä¸èŠ¬èŠ³å°†ä¼ è¾¾å‡ºä½ çš„çˆ±æ„å’Œç¾å¥½ç¥æ„¿ã€‚   \n",
      "2         åº·ä¹ƒé¦¨    20  è¿™æŸå”®ä»·ä»…ä¸º20å…ƒçš„åº·ä¹ƒé¦¨ï¼Œæ˜¯æ‚¨è¡¨è¾¾æ„Ÿæ¿€å’Œæ„Ÿè°¢ä¹‹æƒ…çš„æœ€ä½³é€‰æ‹©ã€‚å®ƒç²¾è‡´çš„èŠ±æœµå’ŒèŠ³é¦™çš„æ°”æ¯å°†ä¸ºæ‚¨...   \n",
      "\n",
      "                                              reason  \n",
      "0  ç²‰è‰²ç«ç‘°è±¡å¾ç€æµªæ¼«å’Œæ¸©æŸ”ï¼Œé€‚åˆé€ç»™å¿ƒçˆ±çš„äººè¡¨è¾¾çˆ±æ„ã€‚é²œè‰³çš„è‰²å½©å’ŒèŠ±é¦™çš„æè¿°èƒ½å¤Ÿå¸å¼•é¡¾å®¢çš„æ³¨æ„...  \n",
      "1  ç™¾åˆä½œä¸ºä¸€ç§ç¾ä¸½çš„é²œèŠ±ï¼Œå…·æœ‰ç‰¹æ®Šçš„è±¡å¾æ„ä¹‰ï¼Œå› æ­¤è¿™æ ·çš„ç®€çŸ­æè¿°èƒ½å¤Ÿçªå‡ºå®ƒçš„ç‹¬ç‰¹ä¹‹å¤„ï¼Œå¸å¼•é¡¾å®¢...  \n",
      "2  åº·ä¹ƒé¦¨æ˜¯ä¸€ç§å«ä¹‰ä¸°å¯Œçš„èŠ±å‰ï¼Œä»£è¡¨ç€æ„Ÿæ¿€ã€æ„Ÿè°¢å’Œæ¬¢æ¬£ã€‚åœ¨è¿™ä¸ªä»·æ ¼å®æƒ çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¼ è¾¾å‡ºæ·±åˆ»çš„æƒ…...  \n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T12:05:51.080301Z",
     "start_time": "2024-07-07T12:05:51.076095Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.to_dict(orient=\"records\"))",
   "id": "93013913949fe14a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'flower_name': 'ç«ç‘°', 'price': '50', 'description': 'è¿™æŸç²‰è‰²ç«ç‘°ï¼ŒèŠ±æœµé¥±æ»¡ï¼Œè‰²å½©é²œè‰³ï¼Œæ•£å‘ç€æ·¡æ·¡çš„èŠ±é¦™ã€‚å®ƒæ˜¯é€ç»™å¿ƒçˆ±çš„äººæœ€ç”œèœœçš„è¡¨ç™½ï¼Œä¹Ÿæ˜¯æœ€æ¸©æŸ”çš„ç¥ç¦ã€‚', 'reason': 'ç²‰è‰²ç«ç‘°è±¡å¾ç€æµªæ¼«å’Œæ¸©æŸ”ï¼Œé€‚åˆé€ç»™å¿ƒçˆ±çš„äººè¡¨è¾¾çˆ±æ„ã€‚é²œè‰³çš„è‰²å½©å’ŒèŠ±é¦™çš„æè¿°èƒ½å¤Ÿå¸å¼•é¡¾å®¢çš„æ³¨æ„ï¼Œè®©ä»–ä»¬äº§ç”Ÿæƒ³è¦è´­ä¹°çš„æ¬²æœ›ã€‚åŒæ—¶ï¼Œå¼ºè°ƒç«ç‘°çš„å«ä¹‰å’Œä½œä¸ºç¤¼ç‰©çš„ç‰¹æ®Šæ„ä¹‰ï¼Œè®©é¡¾å®¢è§‰å¾—è¿™æŸèŠ±ä¸ä»…ä»…æ˜¯ä¸€ä»¶å•†å“ï¼Œæ›´æ˜¯ä¸€ä»½ç‰¹åˆ«çš„å¿ƒæ„ã€‚'}, {'flower_name': 'ç™¾åˆ', 'price': '30', 'description': 'ç™¾åˆï¼Œè±¡å¾ç€çº¯æ´å’Œé«˜è´µï¼Œæ˜¯é€ç»™å¿ƒçˆ±çš„äººæœ€å¥½çš„ç¤¼ç‰©ã€‚è¿™æŸé²œèŠ±çš„å”¯ç¾ä¸èŠ¬èŠ³å°†ä¼ è¾¾å‡ºä½ çš„çˆ±æ„å’Œç¾å¥½ç¥æ„¿ã€‚', 'reason': 'ç™¾åˆä½œä¸ºä¸€ç§ç¾ä¸½çš„é²œèŠ±ï¼Œå…·æœ‰ç‰¹æ®Šçš„è±¡å¾æ„ä¹‰ï¼Œå› æ­¤è¿™æ ·çš„ç®€çŸ­æè¿°èƒ½å¤Ÿçªå‡ºå®ƒçš„ç‹¬ç‰¹ä¹‹å¤„ï¼Œå¸å¼•é¡¾å®¢çš„æ³¨æ„åŠ›ï¼Œè®©ä»–ä»¬æ›´åŠ æ„¿æ„è´­ä¹°ã€‚åŒæ—¶ï¼Œæè¿°ä¸­çš„çˆ±æ„å’Œç¥æ„¿ä¹Ÿèƒ½è®©é¡¾å®¢æ„Ÿå—åˆ°é€ç»™ä»–äººç™¾åˆçš„ç¾å¥½æ„ä¹‰ï¼Œä»è€Œå¢åŠ é”€å”®é‡ã€‚'}, {'flower_name': 'åº·ä¹ƒé¦¨', 'price': '20', 'description': 'è¿™æŸå”®ä»·ä»…ä¸º20å…ƒçš„åº·ä¹ƒé¦¨ï¼Œæ˜¯æ‚¨è¡¨è¾¾æ„Ÿæ¿€å’Œæ„Ÿè°¢ä¹‹æƒ…çš„æœ€ä½³é€‰æ‹©ã€‚å®ƒç²¾è‡´çš„èŠ±æœµå’ŒèŠ³é¦™çš„æ°”æ¯å°†ä¸ºæ‚¨å¸¦æ¥æ— å°½çš„æƒŠå–œå’Œæ„ŸåŠ¨ã€‚', 'reason': 'åº·ä¹ƒé¦¨æ˜¯ä¸€ç§å«ä¹‰ä¸°å¯Œçš„èŠ±å‰ï¼Œä»£è¡¨ç€æ„Ÿæ¿€ã€æ„Ÿè°¢å’Œæ¬¢æ¬£ã€‚åœ¨è¿™ä¸ªä»·æ ¼å®æƒ çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¼ è¾¾å‡ºæ·±åˆ»çš„æƒ…æ„Ÿï¼Œè®©äººä»¬æ„Ÿå—åˆ°çœŸæŒšçš„æƒ…è°Šã€‚å› æ­¤ï¼Œè¿™æ ·çš„æè¿°èƒ½å¤Ÿå¸å¼•é¡¾å®¢çš„æ³¨æ„åŠ›ï¼Œå¹¶è®©ä»–ä»¬äº§ç”Ÿè´­ä¹°çš„æ¬²æœ›ã€‚'}]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T12:06:48.968427Z",
     "start_time": "2024-07-07T12:06:48.965414Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(\"output.csv\", index=False)",
   "id": "2d5bf8a734b655ab",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "210aa76bd826e186"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
